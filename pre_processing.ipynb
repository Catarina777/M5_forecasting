{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reading in the data\n",
    "cal = pd.read_csv('calendar.csv')\n",
    "stv = pd.read_csv('sales_train_validation.csv')\n",
    "ss = pd.read_csv('sample_submission.csv')\n",
    "sellp = pd.read_csv('sell_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downcasting\n",
    "\n",
    "In this step was performed a downcasting of the dataframes to reduce the amount of storage used by them and also to expidite the operations performed on them.\n",
    "\n",
    " - Numerical Columns: Depending on your environment, pandas automatically create int32, int64, float32 or float64 columns for numeric ones. By knowing the min or max value of a column, a subtype can be used to consume less memory. There are the different subtypes:\n",
    "\t- int8 / uint8 : consumes 1 byte of memory, range between -128/127 or 0/255\n",
    "\t- bool : consumes 1 byte, true or false\n",
    " \t- float16 / int16 / uint16: consumes 2 bytes of memory, range between -32768 and 32767 or 0/65535\n",
    "\t- float32 / int32 / uint32 : consumes 4 bytes of memory, range between -2147483648 and 2147483647\n",
    "\t- float64 / int64 / uint64: consumes 8 bytes of memory\n",
    "\n",
    "If one of the column has values between 1 and 10 for example, we can reduce the size of that column from 8 bytes per row to 1 byte, which is more than 85% memory saving on that column!\n",
    "\n",
    " - Categorical Columns: Pandas stores categorical columns as objects. One of the reason this storage is not optimal is that it creates a list of pointers to the memory address of each value of your column. For columns with low cardinality (the amount of unique values is lower than 50% of the count of these values), this can be optimized by forcing pandas to use a virtual mapping table where all unique values are mapped via an integer instead of a pointer. This can be done using the category datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downcast in order to save memory\n",
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "    for i, t in enumerate(types):\n",
    "        if 'int' in str(t):\n",
    "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
    "        elif 'float' in str(t):\n",
    "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
    "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
    "        elif t == object:  # Corrected this line\n",
    "            if cols[i] == 'date':\n",
    "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype('category')\n",
    "    return df\n",
    "\n",
    "# Apply downcast function to the df_m5s\n",
    "stv_downcast = downcast(stv)\n",
    "sellp_downcast = downcast(sellp)\n",
    "cal_downcast = downcast(cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step the \"sales_train_validation\" dataset was melted in order to be able to join its information with oother datasets (such as calendar and sell_prices). \n",
    "\n",
    "What the melt function is doing basically is converting the sales dataframe from wide format to a long format. since variables like id, item_id, dept_id, cat_id, store_id and state_id are important to distinguish each product and the store or state they are sold in, they were kept in the new melted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(stv_downcast, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, cal_downcast, on='d', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5 = pd.merge(df, sellp_downcast, on=['store_id','item_id', 'wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58327365</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58327366</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58327367</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58327368</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58327369</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58327370 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "0         HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1         HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2         HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3         HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4         HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "...                                 ...            ...        ...      ...   \n",
       "58327365    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "58327366    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "58327367    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "58327368    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "58327369    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "         store_id state_id       d  sold       date  wm_yr_wk  ... month  \\\n",
       "0            CA_1       CA     d_1     0 2011-01-29     11101  ...     1   \n",
       "1            CA_1       CA     d_1     0 2011-01-29     11101  ...     1   \n",
       "2            CA_1       CA     d_1     0 2011-01-29     11101  ...     1   \n",
       "3            CA_1       CA     d_1     0 2011-01-29     11101  ...     1   \n",
       "4            CA_1       CA     d_1     0 2011-01-29     11101  ...     1   \n",
       "...           ...      ...     ...   ...        ...       ...  ...   ...   \n",
       "58327365     WI_3       WI  d_1913     1 2016-04-24     11613  ...     4   \n",
       "58327366     WI_3       WI  d_1913     0 2016-04-24     11613  ...     4   \n",
       "58327367     WI_3       WI  d_1913     0 2016-04-24     11613  ...     4   \n",
       "58327368     WI_3       WI  d_1913     3 2016-04-24     11613  ...     4   \n",
       "58327369     WI_3       WI  d_1913     0 2016-04-24     11613  ...     4   \n",
       "\n",
       "          year  event_name_1  event_type_1 event_name_2 event_type_2 snap_CA  \\\n",
       "0         2011           NaN           NaN          NaN          NaN       0   \n",
       "1         2011           NaN           NaN          NaN          NaN       0   \n",
       "2         2011           NaN           NaN          NaN          NaN       0   \n",
       "3         2011           NaN           NaN          NaN          NaN       0   \n",
       "4         2011           NaN           NaN          NaN          NaN       0   \n",
       "...        ...           ...           ...          ...          ...     ...   \n",
       "58327365  2016           NaN           NaN          NaN          NaN       0   \n",
       "58327366  2016           NaN           NaN          NaN          NaN       0   \n",
       "58327367  2016           NaN           NaN          NaN          NaN       0   \n",
       "58327368  2016           NaN           NaN          NaN          NaN       0   \n",
       "58327369  2016           NaN           NaN          NaN          NaN       0   \n",
       "\n",
       "         snap_TX  snap_WI  sell_price  \n",
       "0              0        0         NaN  \n",
       "1              0        0         NaN  \n",
       "2              0        0         NaN  \n",
       "3              0        0         NaN  \n",
       "4              0        0         NaN  \n",
       "...          ...      ...         ...  \n",
       "58327365       0        0    2.980469  \n",
       "58327366       0        0    2.480469  \n",
       "58327367       0        0    3.980469  \n",
       "58327368       0        0    1.280273  \n",
       "58327369       0        0    1.000000  \n",
       "\n",
       "[58327370 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to shortage of memory, the computer used cannot make analysis with such amount of data. To compensate for this the datset was reduced to only have information about the sales of a single item in a store of the California state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for 'CA' state\n",
    "df_fd = df_m5[df_m5['dept_id'] == 'FOODS_1']\n",
    "df_ca = df_fd[df_fd['store_id'] == 'CA_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>FOODS_1_002_CA_1_validation</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.878906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>FOODS_1_003_CA_1_validation</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>FOODS_1_004_CA_1_validation</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>FOODS_1_005_CA_1_validation</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.939453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298703</th>\n",
       "      <td>FOODS_1_215_CA_1_validation</td>\n",
       "      <td>FOODS_1_215</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298704</th>\n",
       "      <td>FOODS_1_216_CA_1_validation</td>\n",
       "      <td>FOODS_1_216</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298705</th>\n",
       "      <td>FOODS_1_217_CA_1_validation</td>\n",
       "      <td>FOODS_1_217</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298706</th>\n",
       "      <td>FOODS_1_218_CA_1_validation</td>\n",
       "      <td>FOODS_1_218</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298707</th>\n",
       "      <td>FOODS_1_219_CA_1_validation</td>\n",
       "      <td>FOODS_1_219</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.240234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413208 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id      item_id  dept_id cat_id store_id  \\\n",
       "1612      FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "1613      FOODS_1_002_CA_1_validation  FOODS_1_002  FOODS_1  FOODS     CA_1   \n",
       "1614      FOODS_1_003_CA_1_validation  FOODS_1_003  FOODS_1  FOODS     CA_1   \n",
       "1615      FOODS_1_004_CA_1_validation  FOODS_1_004  FOODS_1  FOODS     CA_1   \n",
       "1616      FOODS_1_005_CA_1_validation  FOODS_1_005  FOODS_1  FOODS     CA_1   \n",
       "...                               ...          ...      ...    ...      ...   \n",
       "58298703  FOODS_1_215_CA_1_validation  FOODS_1_215  FOODS_1  FOODS     CA_1   \n",
       "58298704  FOODS_1_216_CA_1_validation  FOODS_1_216  FOODS_1  FOODS     CA_1   \n",
       "58298705  FOODS_1_217_CA_1_validation  FOODS_1_217  FOODS_1  FOODS     CA_1   \n",
       "58298706  FOODS_1_218_CA_1_validation  FOODS_1_218  FOODS_1  FOODS     CA_1   \n",
       "58298707  FOODS_1_219_CA_1_validation  FOODS_1_219  FOODS_1  FOODS     CA_1   \n",
       "\n",
       "         state_id       d  sold       date  wm_yr_wk  ... month  year  \\\n",
       "1612           CA     d_1     3 2011-01-29     11101  ...     1  2011   \n",
       "1613           CA     d_1     0 2011-01-29     11101  ...     1  2011   \n",
       "1614           CA     d_1     0 2011-01-29     11101  ...     1  2011   \n",
       "1615           CA     d_1     0 2011-01-29     11101  ...     1  2011   \n",
       "1616           CA     d_1     3 2011-01-29     11101  ...     1  2011   \n",
       "...           ...     ...   ...        ...       ...  ...   ...   ...   \n",
       "58298703       CA  d_1913     0 2016-04-24     11613  ...     4  2016   \n",
       "58298704       CA  d_1913     1 2016-04-24     11613  ...     4  2016   \n",
       "58298705       CA  d_1913     3 2016-04-24     11613  ...     4  2016   \n",
       "58298706       CA  d_1913     6 2016-04-24     11613  ...     4  2016   \n",
       "58298707       CA  d_1913     1 2016-04-24     11613  ...     4  2016   \n",
       "\n",
       "          event_name_1  event_type_1 event_name_2 event_type_2 snap_CA  \\\n",
       "1612               NaN           NaN          NaN          NaN       0   \n",
       "1613               NaN           NaN          NaN          NaN       0   \n",
       "1614               NaN           NaN          NaN          NaN       0   \n",
       "1615               NaN           NaN          NaN          NaN       0   \n",
       "1616               NaN           NaN          NaN          NaN       0   \n",
       "...                ...           ...          ...          ...     ...   \n",
       "58298703           NaN           NaN          NaN          NaN       0   \n",
       "58298704           NaN           NaN          NaN          NaN       0   \n",
       "58298705           NaN           NaN          NaN          NaN       0   \n",
       "58298706           NaN           NaN          NaN          NaN       0   \n",
       "58298707           NaN           NaN          NaN          NaN       0   \n",
       "\n",
       "         snap_TX  snap_WI  sell_price  \n",
       "1612           0        0    2.000000  \n",
       "1613           0        0    7.878906  \n",
       "1614           0        0    2.880859  \n",
       "1615           0        0         NaN  \n",
       "1616           0        0    2.939453  \n",
       "...          ...      ...         ...  \n",
       "58298703       0        0    1.839844  \n",
       "58298704       0        0    5.281250  \n",
       "58298705       0        0    3.539062  \n",
       "58298706       0        0    0.979980  \n",
       "58298707       0        0    2.240234  \n",
       "\n",
       "[413208 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engeneering\n",
    "\n",
    "Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms.\n",
    "\n",
    "There is no concept of input and output features in time series. Instead, we must choose the variable to be predicted and use feature engineering to construct all of the inputs that will be used to make predictions for future time steps.\n",
    "\n",
    "Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems.\n",
    "\n",
    "Introduce lags to the the target variable sold. The maximum lag I have introduced is 28 days (4 weeks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\2103130892.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Lag and Rolling Features\n",
    "# Lag Features\n",
    "lags = 28\n",
    "for lag in range(1, lags + 1):\n",
    "    df_ca[f'sales_lag_{lag}'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a mathematical point of view, mean encoding represents a probability of your target variable, conditional on each value of the feature. In a way, it embodies the target variable in its encoded value. The calculated mean encodings on the basis of following logical features were:\n",
    " - item\n",
    " - state\n",
    " - store\n",
    " - category\n",
    " - department\n",
    " - category and department\n",
    " - store and item\n",
    " - category and item\n",
    " - department and item\n",
    " - state and store\n",
    " - state, store and category\n",
    " - store, category and department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['iteam_sold_avg'] = df_ca.groupby('item_id')['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['state_sold_avg'] = df_ca.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['store_sold_avg'] = df_ca.groupby('store_id')['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['cat_sold_avg'] = df_ca.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['dept_sold_avg'] = df_ca.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['cat_dept_sold_avg'] = df_ca.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['store_item_sold_avg'] = df_ca.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['cat_item_sold_avg'] = df_ca.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['dept_item_sold_avg'] = df_ca.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['state_store_sold_avg'] = df_ca.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['state_store_cat_sold_avg'] = df_ca.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\449548014.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['store_cat_dept_sold_avg'] = df_ca.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n"
     ]
    }
   ],
   "source": [
    "# Mean Encoding Features\n",
    "df_ca['iteam_sold_avg'] = df_ca.groupby('item_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['state_sold_avg'] = df_ca.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['store_sold_avg'] = df_ca.groupby('store_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['cat_sold_avg'] = df_ca.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['dept_sold_avg'] = df_ca.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['cat_dept_sold_avg'] = df_ca.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['store_item_sold_avg'] = df_ca.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['cat_item_sold_avg'] = df_ca.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['dept_item_sold_avg'] = df_ca.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['state_store_sold_avg'] = df_ca.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['state_store_cat_sold_avg'] = df_ca.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_ca['store_cat_dept_sold_avg'] = df_ca.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called the rolling window method because the window would be different for every data point.\n",
    "\n",
    "I'll be calculating weekly rolling avearge of the items sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\3971865725.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['rolling_mean'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window = 7).mean()).astype(np.float16)\n",
      "C:\\Users\\Catarina Ferreira\\AppData\\Local\\Temp\\ipykernel_8056\\3971865725.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ca['rolling_std'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window = 7).std()).astype(np.float16)\n"
     ]
    }
   ],
   "source": [
    "# Rolling Features\n",
    "df_ca['rolling_mean'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window = 7).mean()).astype(np.float16)\n",
    "df_ca['rolling_std'] = df_ca.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window = 7).std()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the new dataframe created after the feature engeneering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 413208 entries, 1612 to 58298707\n",
      "Data columns (total 64 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   id                        413208 non-null  category      \n",
      " 1   item_id                   413208 non-null  category      \n",
      " 2   dept_id                   413208 non-null  category      \n",
      " 3   cat_id                    413208 non-null  category      \n",
      " 4   store_id                  413208 non-null  category      \n",
      " 5   state_id                  413208 non-null  category      \n",
      " 6   d                         413208 non-null  object        \n",
      " 7   sold                      413208 non-null  int16         \n",
      " 8   date                      413208 non-null  datetime64[ns]\n",
      " 9   wm_yr_wk                  413208 non-null  int16         \n",
      " 10  weekday                   413208 non-null  category      \n",
      " 11  wday                      413208 non-null  int8          \n",
      " 12  month                     413208 non-null  int8          \n",
      " 13  year                      413208 non-null  int16         \n",
      " 14  event_name_1              33264 non-null   category      \n",
      " 15  event_type_1              33264 non-null   category      \n",
      " 16  event_name_2              864 non-null     category      \n",
      " 17  event_type_2              864 non-null     category      \n",
      " 18  snap_CA                   413208 non-null  int8          \n",
      " 19  snap_TX                   413208 non-null  int8          \n",
      " 20  snap_WI                   413208 non-null  int8          \n",
      " 21  sell_price                351916 non-null  float16       \n",
      " 22  sales_lag_1               412992 non-null  float16       \n",
      " 23  sales_lag_2               412776 non-null  float16       \n",
      " 24  sales_lag_3               412560 non-null  float16       \n",
      " 25  sales_lag_4               412344 non-null  float16       \n",
      " 26  sales_lag_5               412128 non-null  float16       \n",
      " 27  sales_lag_6               411912 non-null  float16       \n",
      " 28  sales_lag_7               411696 non-null  float16       \n",
      " 29  sales_lag_8               411480 non-null  float16       \n",
      " 30  sales_lag_9               411264 non-null  float16       \n",
      " 31  sales_lag_10              411048 non-null  float16       \n",
      " 32  sales_lag_11              410832 non-null  float16       \n",
      " 33  sales_lag_12              410616 non-null  float16       \n",
      " 34  sales_lag_13              410400 non-null  float16       \n",
      " 35  sales_lag_14              410184 non-null  float16       \n",
      " 36  sales_lag_15              409968 non-null  float16       \n",
      " 37  sales_lag_16              409752 non-null  float16       \n",
      " 38  sales_lag_17              409536 non-null  float16       \n",
      " 39  sales_lag_18              409320 non-null  float16       \n",
      " 40  sales_lag_19              409104 non-null  float16       \n",
      " 41  sales_lag_20              408888 non-null  float16       \n",
      " 42  sales_lag_21              408672 non-null  float16       \n",
      " 43  sales_lag_22              408456 non-null  float16       \n",
      " 44  sales_lag_23              408240 non-null  float16       \n",
      " 45  sales_lag_24              408024 non-null  float16       \n",
      " 46  sales_lag_25              407808 non-null  float16       \n",
      " 47  sales_lag_26              407592 non-null  float16       \n",
      " 48  sales_lag_27              407376 non-null  float16       \n",
      " 49  sales_lag_28              407160 non-null  float16       \n",
      " 50  rolling_mean              411912 non-null  float16       \n",
      " 51  rolling_std               411912 non-null  float16       \n",
      " 52  iteam_sold_avg            413208 non-null  float16       \n",
      " 53  state_sold_avg            413208 non-null  float16       \n",
      " 54  store_sold_avg            413208 non-null  float16       \n",
      " 55  cat_sold_avg              413208 non-null  float16       \n",
      " 56  dept_sold_avg             413208 non-null  float16       \n",
      " 57  cat_dept_sold_avg         413208 non-null  float16       \n",
      " 58  store_item_sold_avg       413208 non-null  float16       \n",
      " 59  cat_item_sold_avg         413208 non-null  float16       \n",
      " 60  dept_item_sold_avg        413208 non-null  float16       \n",
      " 61  state_store_sold_avg      413208 non-null  float16       \n",
      " 62  state_store_cat_sold_avg  413208 non-null  float16       \n",
      " 63  store_cat_dept_sold_avg   413208 non-null  float16       \n",
      "dtypes: category(11), datetime64[ns](1), float16(43), int16(3), int8(5), object(1)\n",
      "memory usage: 54.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>store_sold_avg</th>\n",
       "      <th>cat_sold_avg</th>\n",
       "      <th>dept_sold_avg</th>\n",
       "      <th>cat_dept_sold_avg</th>\n",
       "      <th>store_item_sold_avg</th>\n",
       "      <th>cat_item_sold_avg</th>\n",
       "      <th>dept_item_sold_avg</th>\n",
       "      <th>state_store_sold_avg</th>\n",
       "      <th>state_store_cat_sold_avg</th>\n",
       "      <th>store_cat_dept_sold_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>FOODS_1_002_CA_1_validation</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.477783</td>\n",
       "      <td>0.477783</td>\n",
       "      <td>0.477783</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>FOODS_1_003_CA_1_validation</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>FOODS_1_004_CA_1_validation</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>FOODS_1_005_CA_1_validation</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.162109</td>\n",
       "      <td>1.162109</td>\n",
       "      <td>1.162109</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298703</th>\n",
       "      <td>FOODS_1_215_CA_1_validation</td>\n",
       "      <td>FOODS_1_215</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.100586</td>\n",
       "      <td>1.100586</td>\n",
       "      <td>1.100586</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298704</th>\n",
       "      <td>FOODS_1_216_CA_1_validation</td>\n",
       "      <td>FOODS_1_216</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298705</th>\n",
       "      <td>FOODS_1_217_CA_1_validation</td>\n",
       "      <td>FOODS_1_217</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>2.103516</td>\n",
       "      <td>2.103516</td>\n",
       "      <td>2.103516</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298706</th>\n",
       "      <td>FOODS_1_218_CA_1_validation</td>\n",
       "      <td>FOODS_1_218</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298707</th>\n",
       "      <td>FOODS_1_219_CA_1_validation</td>\n",
       "      <td>FOODS_1_219</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>2.464844</td>\n",
       "      <td>2.464844</td>\n",
       "      <td>2.464844</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>1.374023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413208 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id      item_id  dept_id cat_id store_id  \\\n",
       "1612      FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "1613      FOODS_1_002_CA_1_validation  FOODS_1_002  FOODS_1  FOODS     CA_1   \n",
       "1614      FOODS_1_003_CA_1_validation  FOODS_1_003  FOODS_1  FOODS     CA_1   \n",
       "1615      FOODS_1_004_CA_1_validation  FOODS_1_004  FOODS_1  FOODS     CA_1   \n",
       "1616      FOODS_1_005_CA_1_validation  FOODS_1_005  FOODS_1  FOODS     CA_1   \n",
       "...                               ...          ...      ...    ...      ...   \n",
       "58298703  FOODS_1_215_CA_1_validation  FOODS_1_215  FOODS_1  FOODS     CA_1   \n",
       "58298704  FOODS_1_216_CA_1_validation  FOODS_1_216  FOODS_1  FOODS     CA_1   \n",
       "58298705  FOODS_1_217_CA_1_validation  FOODS_1_217  FOODS_1  FOODS     CA_1   \n",
       "58298706  FOODS_1_218_CA_1_validation  FOODS_1_218  FOODS_1  FOODS     CA_1   \n",
       "58298707  FOODS_1_219_CA_1_validation  FOODS_1_219  FOODS_1  FOODS     CA_1   \n",
       "\n",
       "         state_id       d  sold       date  wm_yr_wk  ... store_sold_avg  \\\n",
       "1612           CA     d_1     3 2011-01-29     11101  ...       1.374023   \n",
       "1613           CA     d_1     0 2011-01-29     11101  ...       1.374023   \n",
       "1614           CA     d_1     0 2011-01-29     11101  ...       1.374023   \n",
       "1615           CA     d_1     0 2011-01-29     11101  ...       1.374023   \n",
       "1616           CA     d_1     3 2011-01-29     11101  ...       1.374023   \n",
       "...           ...     ...   ...        ...       ...  ...            ...   \n",
       "58298703       CA  d_1913     0 2016-04-24     11613  ...       1.374023   \n",
       "58298704       CA  d_1913     1 2016-04-24     11613  ...       1.374023   \n",
       "58298705       CA  d_1913     3 2016-04-24     11613  ...       1.374023   \n",
       "58298706       CA  d_1913     6 2016-04-24     11613  ...       1.374023   \n",
       "58298707       CA  d_1913     1 2016-04-24     11613  ...       1.374023   \n",
       "\n",
       "          cat_sold_avg  dept_sold_avg  cat_dept_sold_avg store_item_sold_avg  \\\n",
       "1612          1.374023       1.374023           1.374023            0.785645   \n",
       "1613          1.374023       1.374023           1.374023            0.477783   \n",
       "1614          1.374023       1.374023           1.374023            0.832031   \n",
       "1615          1.374023       1.374023           1.374023            8.257812   \n",
       "1616          1.374023       1.374023           1.374023            1.162109   \n",
       "...                ...            ...                ...                 ...   \n",
       "58298703      1.374023       1.374023           1.374023            1.100586   \n",
       "58298704      1.374023       1.374023           1.374023            0.776367   \n",
       "58298705      1.374023       1.374023           1.374023            2.103516   \n",
       "58298706      1.374023       1.374023           1.374023           11.703125   \n",
       "58298707      1.374023       1.374023           1.374023            2.464844   \n",
       "\n",
       "         cat_item_sold_avg dept_item_sold_avg state_store_sold_avg  \\\n",
       "1612              0.785645           0.785645             1.374023   \n",
       "1613              0.477783           0.477783             1.374023   \n",
       "1614              0.832031           0.832031             1.374023   \n",
       "1615              8.257812           8.257812             1.374023   \n",
       "1616              1.162109           1.162109             1.374023   \n",
       "...                    ...                ...                  ...   \n",
       "58298703          1.100586           1.100586             1.374023   \n",
       "58298704          0.776367           0.776367             1.374023   \n",
       "58298705          2.103516           2.103516             1.374023   \n",
       "58298706         11.703125          11.703125             1.374023   \n",
       "58298707          2.464844           2.464844             1.374023   \n",
       "\n",
       "          state_store_cat_sold_avg  store_cat_dept_sold_avg  \n",
       "1612                      1.374023                 1.374023  \n",
       "1613                      1.374023                 1.374023  \n",
       "1614                      1.374023                 1.374023  \n",
       "1615                      1.374023                 1.374023  \n",
       "1616                      1.374023                 1.374023  \n",
       "...                            ...                      ...  \n",
       "58298703                  1.374023                 1.374023  \n",
       "58298704                  1.374023                 1.374023  \n",
       "58298705                  1.374023                 1.374023  \n",
       "58298706                  1.374023                 1.374023  \n",
       "58298707                  1.374023                 1.374023  \n",
       "\n",
       "[413208 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca_new = df_ca\n",
    "df_ca_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new dataset in a csv file in order to use it for the prediction models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_new.to_csv('df_ca_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
